[
  
  {
    "title": "AI Applications Observability",
    "url": "/posts/ai-applications-observability/",
    "categories": "Blogging, Tutorial",
    "tags": "agents, llm",
    "date": "2025-04-08 12:08:03 +0300",
    





    
    "snippet": "AI Applications Observabilityhttps://cloud.langfuse.com/",
    "content": "AI Applications Observabilityhttps://cloud.langfuse.com/"
  },
  
  {
    "title": "MCP Servers",
    "url": "/posts/mcp-servers/",
    "categories": "Blogging, Tutorial",
    "tags": "agents, llm",
    "date": "2025-04-07 12:08:03 +0300",
    





    
    "snippet": "MCP ServersThe MCP servers are a set of servers that are used to run the MCP protocol.Hubshttps://glama.ai/mcp/servershttps://smithery.ai/MCP Serverhttps://github.com/mcp-servers/mcp-server",
    "content": "MCP ServersThe MCP servers are a set of servers that are used to run the MCP protocol.Hubshttps://glama.ai/mcp/servershttps://smithery.ai/MCP Serverhttps://github.com/mcp-servers/mcp-server"
  },
  
  {
    "title": "How to build agents with LLMs",
    "url": "/posts/how-to-build-agents-with-llms/",
    "categories": "Blogging, Tutorial",
    "tags": "agents, llm",
    "date": "2025-03-01 11:08:03 +0200",
    





    
    "snippet": "Smolagents        LLamaIndexLlamaHubLlamaHub is a registry of hundreds of integrations, agents and tools that you can use within LlamaIndex.ToolsFunctionTool: Convert any Python function into a too...",
    "content": "Smolagents        LLamaIndexLlamaHubLlamaHub is a registry of hundreds of integrations, agents and tools that you can use within LlamaIndex.ToolsFunctionTool: Convert any Python function into a tool that an agent can use. It automatically figures out how the function works.QueryEngineTool: A tool that lets agents use query engines. Since agents are built on query engines, they can also use other agents as tools.Toolspecs: Sets of tools created by the community, which often include tools for specific services like Gmail.Utility Tools: Special tools that help handle large amounts of data from other tools.Agent typesFunction Calling Agents - These work with AI models that can call specific functions.ReAct Agents - These can work with any AI that does chat or text endpoint and deal with complex reasoning tasks.Advanced Custom Agents - These use more complex methods to deal with more complex tasks and workflows.from llama_index.llms.huggingface_api import HuggingFaceInferenceAPIfrom llama_index.core.agent.workflow import AgentWorkflowfrom llama_index.core.tools import FunctionTool# define sample Tool -- type annotations, function names, and docstrings, are all included in parsed schemas!def multiply(a: int, b: int) -&gt; int:    \"\"\"Multiplies two integers and returns the resulting integer\"\"\"    return a * b# initialize llmllm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")# initialize agentagent = AgentWorkflow.from_tools_or_functions(    [FunctionTool.from_defaults(multiply)],    llm=llm)Agents are stateless by default. They can be made stateful by using a Context:# statelessresponse = await agent.run(\"What is 2 times 2?\")# remembering statefrom llama_index.core.workflow import Contextctx = Context(agent)response = await agent.run(\"My name is Bob.\", ctx=ctx)response = await agent.run(\"What was my name again?\", ctx=ctx)Creating RAG Agents with QueryEngineToolsfrom llama_index.core.tools import QueryEngineToolquery_engine = index.as_query_engine(llm=llm, similarity_top_k=3)query_engine_tool = QueryEngineTool.from_defaults(    query_engine=query_engine,    name=\"name\",    description=\"a specific description\",    return_direct=False,)query_engine_agent = AgentWorkflow.from_tools_or_functions(    [query_engine_tool],    llm=llm,    system_prompt=\"You are a helpful assistant that has access to a database containing persona descriptions. \")Creating Multi-agent systemsfrom llama_index.core.agent.workflow import (    AgentWorkflow,    FunctionAgent,    ReActAgent,)# Define some toolsdef add(a: int, b: int) -&gt; int:    \"\"\"Add two numbers.\"\"\"    return a + bdef subtract(a: int, b: int) -&gt; int:    \"\"\"Subtract two numbers.\"\"\"    return a - b# Create agent configs# NOTE: we can use FunctionAgent or ReActAgent here.# FunctionAgent works for LLMs with a function calling API.# ReActAgent works for any LLM.calculator_agent = ReActAgent(    name=\"calculator\",    description=\"Performs basic arithmetic operations\",    system_prompt=\"You are a calculator assistant. Use your tools for any math operation.\",    tools=[add, subtract],    llm=llm,)query_agent = ReActAgent(    name=\"info_lookup\",    description=\"Looks up information about XYZ\",    system_prompt=\"Use your tool to query a RAG system to answer information about XYZ\",    tools=[query_engine_tool],    llm=llm)# Create and run the workflowagent = AgentWorkflow(    agents=[calculator_agent, query_agent], root_agent=\"calculator\")# Run the systemresponse = await agent.run(user_msg=\"Can you add 5 and 3?\")Creating agentic workflows in LlamaIndexA workflow in LlamaIndex provides a structured way to organize your code into sequential and manageable steps.Such a workflow is created by defining Steps which are triggered by Events, and themselves emit Events to trigger further steps.A single step workflowfrom llama_index.core.workflow import StartEvent, StopEvent, Workflow, stepclass MyWorkflow(Workflow):    @step    async def my_step(self, ev: StartEvent) -&gt; StopEvent:        # do something here        return StopEvent(result=\"Hello, world!\")w = MyWorkflow(timeout=10, verbose=False)result = await w.run()Connecting Multiple Stepsfrom llama_index.core.workflow import Eventclass ProcessingEvent(Event):    intermediate_result: strclass MultiStepWorkflow(Workflow):    @step    async def step_one(self, ev: StartEvent) -&gt; ProcessingEvent:        # Process initial data        return ProcessingEvent(intermediate_result=\"Step 1 complete\")    @step    async def step_two(self, ev: ProcessingEvent) -&gt; StopEvent:        # Use the intermediate result        final_result = f\"Finished processing: {ev.intermediate_result}\"        return StopEvent(result=final_result)w = MultiStepWorkflow(timeout=10, verbose=False)result = await w.run()resultLoops and Branchesfrom llama_index.core.workflow import Eventimport randomclass ProcessingEvent(Event):    intermediate_result: strclass LoopEvent(Event):    loop_output: strclass MultiStepWorkflow(Workflow):    @step    async def step_one(self, ev: StartEvent | LoopEvent) -&gt; ProcessingEvent | LoopEvent:        if random.randint(0, 1) == 0:            print(\"Bad thing happened\")            return LoopEvent(loop_output=\"Back to step one.\")        else:            print(\"Good thing happened\")            return ProcessingEvent(intermediate_result=\"First step complete.\")    @step    async def step_two(self, ev: ProcessingEvent) -&gt; StopEvent:        # Use the intermediate result        final_result = f\"Finished processing: {ev.intermediate_result}\"        return StopEvent(result=final_result)w = MultiStepWorkflow(verbose=False)result = await w.run()resultDrawing Workflowsfrom llama_index.utils.workflow import draw_all_possible_flowsw = ... # as defined in the previous sectiondraw_all_possible_flows(w, \"flow.html\")State Managementfrom llama_index.core.workflow import Context, StartEvent, StopEvent@stepasync def query(self, ctx: Context, ev: StartEvent) -&gt; StopEvent:    # store query in the context    await ctx.set(\"query\", \"What is the capital of France?\")    # do something with context and event    val = ...    # retrieve query from the context    query = await ctx.get(\"query\")    return StopEvent(result=val)Automating workflows with Multi-Agent Workflowsfrom llama_index.core.agent.workflow import AgentWorkflow, ReActAgentfrom llama_index.llms.huggingface_api import HuggingFaceInferenceAPI# Define some toolsdef add(a: int, b: int) -&gt; int:    \"\"\"Add two numbers.\"\"\"    return a + bdef multiply(a: int, b: int) -&gt; int:    \"\"\"Multiply two numbers.\"\"\"    return a * bllm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")# we can pass functions directly without FunctionTool -- the fn/docstring are parsed for the name/descriptionmultiply_agent = ReActAgent(    name=\"multiply_agent\",    description=\"Is able to multiply two integers\",    system_prompt=\"A helpful assistant that can use a tool to multiply numbers.\",    tools=[multiply],    llm=llm,)addition_agent = ReActAgent(    name=\"add_agent\",    description=\"Is able to add two integers\",    system_prompt=\"A helpful assistant that can use a tool to add numbers.\",    tools=[add],    llm=llm,)# Create the workflowworkflow = AgentWorkflow(    agents=[multiply_agent, addition_agent],    root_agent=\"multiply_agent\",)# Run the systemresponse = await workflow.run(user_msg=\"Can you add 5 and 3?\")State Managementfrom llama_index.core.workflow import Context# Define some toolsasync def add(ctx: Context, a: int, b: int) -&gt; int:    \"\"\"Add two numbers.\"\"\"    # update our count    cur_state = await ctx.get(\"state\")    cur_state[\"num_fn_calls\"] += 1    await ctx.set(\"state\", cur_state)    return a + basync def multiply(ctx: Context, a: int, b: int) -&gt; int:    \"\"\"Multiply two numbers.\"\"\"    # update our count    cur_state = await ctx.get(\"state\")    cur_state[\"num_fn_calls\"] += 1    await ctx.set(\"state\", cur_state)    return a * b...workflow = AgentWorkflow(    agents=[multiply_agent, addition_agent],    root_agent=\"multiply_agent\"    initial_state={\"num_fn_calls\": 0},    state_prompt=\"Current state: {state}. User message: {msg}\",)# run the workflow with contextctx = Context(workflow)response = await workflow.run(user_msg=\"Can you add 5 and 3?\", ctx=ctx)# pull out and inspect the statestate = await ctx.get(\"state\")print(state[\"num_fn_calls\"])LangGraphThe key scenarios where LangGraph excels include:  Multi-step reasoning processes that need explicit control on the flow  Applications requiring persistence of state between steps  Systems that combine deterministic logic with AI capabilities  Workflows that need human-in-the-loop interventions  Complex agent architectures with multiple components working togetherLangGraph ComponentsAt its core, LangGraph uses a directed graph structure to define the flow of your application:  Nodes represent individual processing steps (like calling an LLM, using a tool, or making a decision).  Edges define the possible transitions between steps.  State is user defined and maintained and passed between nodes during execution. When deciding which node to target next, this is the current state that we look at.StateIt represents all the information that flows through your application.from typing_extensions import TypedDictclass State(TypedDict):    graph_state: strNodesNodes are python functions. Each node:  Takes the state as input  Performs some operation  Returns updates to the stateNodes can contain:  LLM calls: Generate text or make decisions  Tool calls: Interact with external systems  Conditional logic: Determine next steps  Human intervention: Get input from usersdef node_1(state):    print(\"---Node 1---\")    return {\"graph_state\": state['graph_state'] +\" I am\"}def node_2(state):    print(\"---Node 2---\")    return {\"graph_state\": state['graph_state'] +\" happy!\"}def node_3(state):    print(\"---Node 3---\")    return {\"graph_state\": state['graph_state'] +\" sad!\"}EdgesEdges connect nodes and define the possible paths through your graph:import randomfrom typing import Literaldef decide_mood(state) -&gt; Literal[\"node_2\", \"node_3\"]:        # Often, we will use state to decide on the next node to visit    user_input = state['graph_state']         # Here, let's just do a 50 / 50 split between nodes 2, 3    if random.random() &lt; 0.5:        # 50% of the time, we return Node 2        return \"node_2\"        # 50% of the time, we return Node 3    return \"node_3\"StateGraphThe StateGraph is the main component that ties everything together. It defines the nodes and edges, and manages the state as the graph is executed.from IPython.display import Image, displayfrom langgraph.graph import StateGraph, START, END# Build graphbuilder = StateGraph(State)builder.add_node(\"node_1\", node_1)builder.add_node(\"node_2\", node_2)builder.add_node(\"node_3\", node_3)# Logicbuilder.add_edge(START, \"node_1\")builder.add_conditional_edges(\"node_1\", decide_mood)builder.add_edge(\"node_2\", END)builder.add_edge(\"node_3\", END)# Addgraph = builder.compile()ExampleLet’s say we have an email processing system, where he needs to:  Read incoming emails  Classify them as spam or legitimate  Draft a preliminary response for legitimate emails  Send information to Mr. Wayne when legitimate (printing only)Stateclass EmailState(TypedDict):    # The email being processed    email: Dict[str, Any]  # Contains subject, sender, body, etc.    # Category of the email (inquiry, complaint, etc.)    email_category: Optional[str]    # Reason why the email was marked as spam    spam_reason: Optional[str]    # Analysis and decisions    is_spam: Optional[bool]        # Response generation    email_draft: Optional[str]        # Processing metadata    messages: List[Dict[str, Any]]  # Track conversation with LLM for analysisNodes# Initialize our LLMmodel = ChatOpenAI(temperature=0)def read_email(state: EmailState):    \"\"\"Alfred reads and logs the incoming email\"\"\"    email = state[\"email\"]        # Here we might do some initial preprocessing    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")        # No state changes needed here    return {}def classify_email(state: EmailState):    \"\"\"Alfred uses an LLM to determine if the email is spam or legitimate\"\"\"    email = state[\"email\"]        # Prepare our prompt for the LLM    prompt = f\"\"\"    As Alfred the butler, analyze this email and determine if it is spam or legitimate.        Email:    From: {email['sender']}    Subject: {email['subject']}    Body: {email['body']}        First, determine if this email is spam. If it is spam, explain why.    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).    \"\"\"        # Call the LLM    messages = [HumanMessage(content=prompt)]    response = model.invoke(messages)        # Simple logic to parse the response (in a real app, you'd want more robust parsing)    response_text = response.content.lower()    is_spam = \"spam\" in response_text and \"not spam\" not in response_text        # Extract a reason if it's spam    spam_reason = None    if is_spam and \"reason:\" in response_text:        spam_reason = response_text.split(\"reason:\")[1].strip()        # Determine category if legitimate    email_category = None    if not is_spam:        categories = [\"inquiry\", \"complaint\", \"thank you\", \"request\", \"information\"]        for category in categories:            if category in response_text:                email_category = category                break        # Update messages for tracking    new_messages = state.get(\"messages\", []) + [        {\"role\": \"user\", \"content\": prompt},        {\"role\": \"assistant\", \"content\": response.content}    ]        # Return state updates    return {        \"is_spam\": is_spam,        \"spam_reason\": spam_reason,        \"email_category\": email_category,        \"messages\": new_messages    }def handle_spam(state: EmailState):    \"\"\"Alfred discards spam email with a note\"\"\"    print(f\"Alfred has marked the email as spam. Reason: {state['spam_reason']}\")    print(\"The email has been moved to the spam folder.\")        # We're done processing this email    return {}def draft_response(state: EmailState):    \"\"\"Alfred drafts a preliminary response for legitimate emails\"\"\"    email = state[\"email\"]    category = state[\"email_category\"] or \"general\"        # Prepare our prompt for the LLM    prompt = f\"\"\"    As Alfred the butler, draft a polite preliminary response to this email.        Email:    From: {email['sender']}    Subject: {email['subject']}    Body: {email['body']}        This email has been categorized as: {category}        Draft a brief, professional response that Mr. Hugg can review and personalize before sending.    \"\"\"        # Call the LLM    messages = [HumanMessage(content=prompt)]    response = model.invoke(messages)        # Update messages for tracking    new_messages = state.get(\"messages\", []) + [        {\"role\": \"user\", \"content\": prompt},        {\"role\": \"assistant\", \"content\": response.content}    ]        # Return state updates    return {        \"email_draft\": response.content,        \"messages\": new_messages    }def notify_mr_hugg(state: EmailState):    \"\"\"Alfred notifies Mr. Hugg about the email and presents the draft response\"\"\"    email = state[\"email\"]        print(\"\\n\" + \"=\"*50)    print(f\"Sir, you've received an email from {email['sender']}.\")    print(f\"Subject: {email['subject']}\")    print(f\"Category: {state['email_category']}\")    print(\"\\nI've prepared a draft response for your review:\")    print(\"-\"*50)    print(state[\"email_draft\"])    print(\"=\"*50 + \"\\n\")        # We're done processing this email    return {}Routing Logicdef route_email(state: EmailState) -&gt; str:    \"\"\"Determine the next step based on spam classification\"\"\"    if state[\"is_spam\"]:        return \"spam\"    else:        return \"legitimate\"StateGraph and Edges# Create the graphemail_graph = StateGraph(EmailState)# Add nodesemail_graph.add_node(\"read_email\", read_email)email_graph.add_node(\"classify_email\", classify_email)email_graph.add_node(\"handle_spam\", handle_spam)email_graph.add_node(\"draft_response\", draft_response)email_graph.add_node(\"notify_mr_hugg\", notify_mr_hugg)# Start the edgesemail_graph.add_edge(START, \"read_email\")# Add edges - defining the flowemail_graph.add_edge(\"read_email\", \"classify_email\")# Add conditional branching from classify_emailemail_graph.add_conditional_edges(    \"classify_email\",    route_email,    {        \"spam\": \"handle_spam\",        \"legitimate\": \"draft_response\"    })# Add the final edgesemail_graph.add_edge(\"handle_spam\", END)email_graph.add_edge(\"draft_response\", \"notify_mr_hugg\")email_graph.add_edge(\"notify_mr_hugg\", END)# Compile the graphcompiled_graph = email_graph.compile()Running the graph# Example legitimate emaillegitimate_email = {    \"sender\": \"john.smith@example.com\",    \"subject\": \"Question about your services\",    \"body\": \"Dear Mr. Hugg, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"}# Example spam emailspam_email = {    \"sender\": \"winner@lottery-intl.com\",    \"subject\": \"YOU HAVE WON $5,000,000!!!\",    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"}# Process the legitimate emailprint(\"\\nProcessing legitimate email...\")legitimate_result = compiled_graph.invoke({    \"email\": legitimate_email,    \"is_spam\": None,    \"spam_reason\": None,    \"email_category\": None,    \"email_draft\": None,    \"messages\": []})# Process the spam emailprint(\"\\nProcessing spam email...\")spam_result = compiled_graph.invoke({    \"email\": spam_email,    \"is_spam\": None,    \"spam_reason\": None,    \"email_category\": None,    \"email_draft\": None,    \"messages\": []})Observing the graphLangGraph integrates with the LangFuse platform, which allows you to observe the graph as it is executed."
  },
  
  {
    "title": "Function Calling with Mistral",
    "url": "/posts/Function-Calling-with-Mistral/",
    "categories": "Blogging, Tutorial",
    "tags": "agents, llm",
    "date": "2025-02-25 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Agents Building Blocks",
    "url": "/posts/Agents-Building-blocks/",
    "categories": "",
    "tags": "",
    "date": "2025-02-14 00:00:00 +0200",
    





    
    "snippet": "title:  “Agents building blocks”description: &gt;-  Agents building blocks.author: lsodate:   2025-02-14 11:08:03 +0200categories: [Blogging, Tutorial]tags: [agents,llm]pin: falsemedia_subpath: ‘/p...",
    "content": "title:  “Agents building blocks”description: &gt;-  Agents building blocks.author: lsodate:   2025-02-14 11:08:03 +0200categories: [Blogging, Tutorial]tags: [agents,llm]pin: falsemedia_subpath: ‘/posts/20250214’—What is an agent?An agent is an AI model capable of reasoning, planning, and interacting with its environment. We call it Agent because it has agency, aka it has the ability to interact with the environment.The main steps of an agent are:  Reasoning  Planning  Action Execution by using toolsAgent’s brain - the LLMMost LLMs nowadays are built on the Transformer architecture—a deep learning architecture based on the “Attention” algorithm, that has gained significant interest since the release of BERT from Google in 2018.There are 3 types of transformers :  Encoder: An encoder-based Transformer takes text (or other data) as input and outputs a dense representation (or embedding) of that text. Use Cases: Text classification, semantic search, Named Entity Recognition.  Decoder: A decoder-based Transformer focuses on generating new tokens to complete a sequence, one token at a time. Use Cases: Text generation, chatbots, code generation  Seq2Seq (Encoder–Decoder): A sequence-to-sequence Transformer combines an encoder and a decoder. The encoder first processes the input sequence into a context representation, then the decoder generates an output sequence. Use Cases: Translation, Summarization, Paraphrasing.Although Large Language Models come in various forms, LLMs are typically decoder-based models with billions of parameters.The underlying principle of an LLM is simple yet highly effective: its objective is to predict the next token, given a sequence of previous tokens. A “token” is the unit of information an LLM works with. You can think of a “token” as if it was a “word”, but for efficiency reasons LLMs don’t use whole words.For example, while English has an estimated 600,000 words, an LLM might have a vocabulary of around 32,000 tokens (as is the case with Llama 2). Tokenization often works on sub-word units that can be combined.Each LLM has some special tokens specific to the model. The LLM uses these tokens to open and close the structured components of its generation. For example, to indicate the start or end of a sequence, message, or response. Moreover, the input prompts that we pass to the model are also structured with special tokens. The most important of those is the End of sequence token (EOS).LLMs are said to be autoregressive, meaning that the output from one pass becomes the input for the next one. This loop continues until the model predicts the next token to be the EOS token, at which point the model can stop.System MessagesSystem messages (also called System Prompts) define how the model should behave. They serve as persistent instructions, guiding every subsequent interaction.system_message = {    \"role\": \"system\",    \"content\": \"You are a professional customer service agent. Always be polite, clear, and helpful.\"}When using Agents, the System Message also gives information about the available tools, provides instructions to the model on how to format the actions to take, and includes guidelines on how the thought process should be segmented.Conversations: User and Assistant MessagesA conversation consists of alternating messages between a Human (user) and an LLM (assistant).Chat templates help maintain context by preserving conversation history, storing previous exchanges between the user and the assistant. This leads to more coherent multi-turn conversations.conversation = [    {\"role\": \"user\", \"content\": \"I need help with my order\"},    {\"role\": \"assistant\", \"content\": \"I'd be happy to help. Could you provide your order number?\"},    {\"role\": \"user\", \"content\": \"It's ORDER-123\"},]For example, this is how the SmolLM2 chat template would format the previous exchange into a prompt:&lt;|im_start|&gt;systemYou are a helpful AI assistant named SmolLM, trained by Hugging Face&lt;|im_end|&gt;&lt;|im_start|&gt;userI need help with my order&lt;|im_end|&gt;&lt;|im_start|&gt;assistantI'd be happy to help. Could you provide your order number?&lt;|im_end|&gt;&lt;|im_start|&gt;userIt's ORDER-123&lt;|im_end|&gt;&lt;|im_start|&gt;assistantHowever, the same conversation would be translated into the following prompt when using Llama 3.2:&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;Cutting Knowledge Date: December 2023Today Date: 10 Feb 2025&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;I need help with my order&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;I'd be happy to help. Could you provide your order number?&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;It's ORDER-123&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;Chat-TemplatesChat templates are essential for structuring conversations between language models and users. They guide how message exchanges are formatted into a single prompt.Base Models vs. Instruct ModelsA Base Model is trained on raw text data to predict the next token.An Instruct Model is fine-tuned specifically to follow instructions and engage in conversations. For example, SmolLM2-135M is a base model, while SmolLM2-135M-Instruct is its instruction-tuned variant.To make a Base Model behave like an instruct model, we need to format our prompts in a consistent way that the model can understand. This is where chat templates come in.To make a Base Model behave like an instruct model, we need to format our prompts in a consistent way that the model can understand. This is where chat templates come in.It’s important to note that a base model could be fine-tuned on different chat templates, so when we’re using an instruct model we need to make sure we’re using the correct chat template.Because each instruct model uses different conversation formats and special tokens, chat templates are implemented to ensure that we correctly format the prompt the way each model expects.Below is a simplified version of the SmolLM2-135M-Instruct chat template:Given these messages:messages = [    {\"role\": \"system\", \"content\": \"You are a helpful assistant focused on technical topics.\"},    {\"role\": \"user\", \"content\": \"Can you explain what a chat template is?\"},    {\"role\": \"assistant\", \"content\": \"A chat template structures conversations between users and AI models...\"},    {\"role\": \"user\", \"content\": \"How do I use it ?\"},]The chat template will format them as follows:&lt;|im_start|&gt;systemYou are a helpful assistant focused on technical topics.&lt;|im_end|&gt;&lt;|im_start|&gt;userCan you explain what a chat template is?&lt;|im_end|&gt;&lt;|im_start|&gt;assistantA chat template structures conversations between users and AI models...&lt;|im_end|&gt;&lt;|im_start|&gt;userHow do I use it ?&lt;|im_end|&gt;The transformers library will take care of chat templates for you as part of the tokenization process.Messages to promptThe easiest way to ensure your LLM receives a conversation correctly formatted is to use the chat_template from the model’s tokenizer.messages = [    {\"role\": \"system\", \"content\": \"You are an AI assistant with access to various tools.\"},    {\"role\": \"user\", \"content\": \"Hi !\"},    {\"role\": \"assistant\", \"content\": \"Hi human, what can help you with ?\"},]To convert the previous conversation into a prompt, we load the tokenizer and call apply_chat_template:from transformers import AutoTokenizertokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")rendered_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)The rendered_prompt returned by this function is now ready to use as the input for the model you chose!What are Tools?One crucial aspect of AI Agents is their ability to take actions. As we saw, this happens through the use of Tools.By giving your Agent the right Tools—and clearly describing how those Tools work—you can dramatically increase what your AI can accomplish.ATool is a function given to the LLM. This function should fulfill a clear objective. you can in fact create a tool for any use case! For instance, if you need to perform arithmetic, giving a calculator tool to your LLM will provide better results than relying on the native capabilities of the model.For instance, if you need to perform arithmetic, giving a calculator tool to your LLM will provide better results than relying on the native capabilities of the model. For instance, if you ask an LLM directly (without a search tool) for today’s weather, the LLM will potentially hallucinate random weather.A Tool contains:  A textual description of what the function does.  A Callable (something to perform an action).  Arguments with typings.  (Optional) Outputs with typings.How do tools work?LLMs, as we saw, can only receive text inputs and generate text outputs. They have no way to call tools on their own. What we mean when we talk about providing tools to an Agent, is that we teach the LLM about the existence of tools, and ask the model to generate text that will invoke tools when it needs to. For example, if we provide a tool to check the weather at a location from the Internet, and then ask the LLM about the weather in Paris, the LLM will recognize that question as a relevant opportunity to use the “weather” tool we taught it about. The LLM will generate text, in the form of code, to invoke that tool. It is the responsibility of the Agent to parse the LLM’s output, recognize that a tool call is required, and invoke the tool on the LLM’s behalf. The output from the tool will then be sent back to the LLM, which will compose its final response for the user.How do we give tools to an LLM?Use the system prompt to provide textual descriptions of available tools to the model:system_message = \"\"\"You are a helpful assistant with access to the following tools: weather, calculator, and search. You can use these tools:{tool_description}\"\"\"We will implement a simplified calculator tool that will just multiply two integers. This could be our Python implementation:def calculator(a: int, b: int) -&gt; int:    \"\"\"Multiply two integers.\"\"\"    return a * bprint(calculator.to_string())So our tool is called calculator, it multiplies two integers, and it requires the following inputs:a (int): An integer.b (int): An integer.The output of the tool is another integer number that we can describe like this:(int): The product of a and b.All of these details are important. Let’s put them together in a text string that describes our tool for the LLM to understand.Tool Name: calculator, Description: Multiply two integers., Arguments: a: int, b: int, Outputs: intThis textual description is what we want the LLM to know about the tool.Auto-formatting Tool sectionsOur tool was written in Python, and the implementation already provides everything we need:  A descriptive name of what it does: calculator  A longer description, provided by the function’s docstring comment: Multiply two integers.  The inputs and their type: the function clearly expects two ints.  The type of the output.We could provide the Python source code as the specification of the tool for the LLM, but the way the tool is implemented does not matter. All that matters is its name, what it does, the inputs it expects and the output it provides.We will leverage Python’s introspection features to leverage the source code and build a tool description automatically for us. All we need is that the tool implementation uses type hints, docstrings, and sensible function names. We will write some code to extract the relevant portions from the source code.After we are done, we’ll only need to use a Python decorator to indicate that the calculator function is a tool:@tooldef calculator(a: int, b: int) -&gt; int:    \"\"\"Multiply two integers.\"\"\"    return a * bprint(calculator.to_string())With the tool decorator implementation, we will be able to retrieve the following text automatically from the source code:Tool Name: calculator, Description: Multiply two integers., Arguments: a: int, b: int, Outputs: intThis is a simplified example, but it shows the power of tools. We can now use the calculator tool in our system prompt:class Tool:    \"\"\"    A class representing a reusable piece of code (Tool).        Attributes:        name (str): Name of the tool.        description (str): A textual description of what the tool does.        func (callable): The function this tool wraps.        arguments (list): A list of argument.        outputs (str or list): The return type(s) of the wrapped function.    \"\"\"    def __init__(self,                  name: str,                  description: str,                  func: callable,                  arguments: list,                 outputs: str):        self.name = name        self.description = description        self.func = func        self.arguments = arguments        self.outputs = outputs    def to_string(self) -&gt; str:        \"\"\"        Return a string representation of the tool,         including its name, description, arguments, and outputs.        \"\"\"        args_str = \", \".join([            f\"{arg_name}: {arg_type}\" for arg_name, arg_type in self.arguments        ])                return (            f\"Tool Name: {self.name},\"            f\" Description: {self.description},\"            f\" Arguments: {args_str},\"            f\" Outputs: {self.outputs}\"        )    def __call__(self, *args, **kwargs):        \"\"\"        Invoke the underlying function (callable) with provided arguments.        \"\"\"        return self.func(*args, **kwargs)def tool(func):    \"\"\"    A decorator that creates a Tool instance from the given function.    \"\"\"    # Get the function signature    signature = inspect.signature(func)        # Extract (param_name, param_annotation) pairs for inputs    arguments = []    for param in signature.parameters.values():        annotation_name = (            param.annotation.__name__             if hasattr(param.annotation, '__name__')             else str(param.annotation)        )        arguments.append((param.name, annotation_name))        # Determine the return annotation    return_annotation = signature.return_annotation    if return_annotation is inspect._empty:        outputs = \"No return annotation\"    else:        outputs = (            return_annotation.__name__             if hasattr(return_annotation, '__name__')             else str(return_annotation)        )        # Use the function's docstring as the description (default if None)    description = func.__doc__ or \"No description provided.\"        # The function name becomes the Tool name    name = func.__name__        # Return a new Tool instance    return Tool(        name=name,         description=description,         func=func,         arguments=arguments,         outputs=outputs    )The decorator description is injected in the system prompt. Taking the example with which we started this section, here is how it would look like after replacing the tools_description:Understanding AI Agents through the Thought-Action-Observation CycleAgents work in a continuous cycle of: thinking (Thought) → acting (Act) and observing (Observe).Let’s break down these actions together:  Thought: The LLM part of the Agent decides what the next step should be.  Action: The agent takes an action, by calling the tools with the associated arguments.  Observation: The model reflects on the response from the tool.The Thought-Action-Observation CycleIn many Agent frameworks, the rules and guidelines are embedded directly into the system prompt, ensuring that every cycle adheres to a defined logic.system_message=\"\"\"You are an AI assistant designed to help users efficiently and accurately. Your primary goal is to provide helpful, precise, and clear responses.You have access to the following tools:Tool Name: calculator, Description: Multiply two integers., Arguments: a: int, b: int, Outputs: intYou should think step by step in order to fulfill the objective with a reasoning devided in Thought/Action/Observation that can repeat multiple times if needed.You should first reflect with ‘Thought: {your_thoughts}’ on the current situation, then (if necessary ), call a tool with the proper JSON formatting ‘Action: {JSON_BLOB}’,or you print your final answer starting with the prefix ‘Final Answer:’\"\"\"The weather AgentA user asks the agent: “What’s the weather like in New York today?”Alfred’s job is to answer this query using a weather API tool.Thought: “The user needs current weather information for New York. I have access to a tool that fetches weather data. First, I need to call the weather API to get up-to-date details.”Action: Based on its reasoning and the fact that Alfred knows about a get_weather tool, Alfred prepares a JSON-formatted command that calls the weather API tool.Observation: After the tool call, Alfred receives an observation. This might be the raw weather data from the API such as: “Current weather in New York: partly cloudy, 15°C, 60% humidity.” This observation is then added to the prompt as additional context. It functions as real-world feedback, confirming whether the action succeeded and providing the needed details.Updated thought: “Now that I have the weather data for New York, I can compile an answer for the user.”Final Action: Thought: I have the weather data now. The current weather in New York is partly cloudy with a temperature of 15°C and 60% humidity.”Final answer : The current weather in New York is partly cloudy with a temperature of 15°C and 60% humidity.ReAct cycleThe interplay of Thought, Action, and Observation empowers AI agents to solve complex tasks iteratively.By understanding and applying these principles, you can design agents that not only reason about their tasks but also effectively utilize external tools to complete them, all while continuously refining their output based on environmental feedback.Thought: Internal Reasoning and the Re-Act ApproachType of Thought:  Planning: “I need to break this task into three steps: 1) gather data, 2) analyze trends, 3) generate report”  Analysis: “Based on the error message, the issue appears to be with the database connection parameters”  Decision Making: “Given the user’s budget constraints, I should recommend the mid-tier option”  Problem Solving: “To optimize this code, I should first profile it to identify bottlenecks”  Memory Integration: “The user mentioned their preference for Python earlier, so I’ll provide examples in Python”  Self-Reflection: “My last approach didn’t work well, I should try a different strategy”  Goal Setting: “To complete this task, I need to first establish the acceptance criteria”  Prioritization: “The security vulnerability should be addressed before adding new features”Action: External Tool InvocationType of Action:  API Call: “I need to call the weather API to get the current weather in New York”  Function Call: “I need to call the get_weather function with the appropriate arguments”The Re-Act ApproachA key method is the ReAct approach, which is the concatenation of “Reasoning” (Think) with “Acting” (Act).ReAct is a simple prompting technique that appends “Let’s think step by step” before letting the LLM decode the next tokens.Indeed, prompting the model to think “step by step” encourages the decoding process toward next tokens that generate a plan, rather than a final solution, since the model is encouraged to decompose the problem into sub-tasks.This allows the model to consider sub-steps in more detail, which in general leads to less errors than trying to generate the final solution directly.Models like Deepseek R1 or OpenAI’s o1, which have been fine-tuned to “think before answering”.These models have been trained to always include specific thinking sections (enclosed between  and  special tokens). This is not just a prompting technique like ReAct, but a training method where the model learns to generate these sections after analyzing thousands of examples that show what we expect it to do.Actions: Enabling the Agent to Engage with Its EnvironmentActions are the concrete steps an AI agent takes to interact with its environment.Whether it’s browsing the web for information or controlling a physical device, each action is a deliberate operation executed by the agent.Types of Agent Actions:  JSON Agent: The Action to take is specified in JSON format.  Code Agent: The Agent writes a code block that is interpreted externally.  Function-calling Agent: It is a subcategory of the JSON Agent which has been fine-tuned to generate a new message for each action.Type of Action:  Information Gathering: Performing web searches, querying databases, or retrieving documents.  Tool Usage: Making API calls, running calculations, and executing code.  Environment Interaction: Manipulating digital interfaces or controlling physical devices.  Communication: Engaging with users via chat or collaborating with other agents.One crucial part of an agent is the ability to STOP generating new tokens when an action is complete, and that is true for all formats of Agent: JSON, code, or function-calling. This prevents unintended output and ensures that the agent’s response is clear and precise.The Stop and Parse ApproachOne key method for implementing actions is the stop and parse approach. This method ensures that the agent’s output is structured and predictable:Generation in a Structured Format: The agent outputs its intended action in a clear, predetermined format (JSON or code).Halting Further Generation: Once the action is complete, the agent stops generating additional tokens. This prevents extra or erroneous output.Parsing the Output: An external parser reads the formatted action, determines which Tool to call, and extracts the required parameters.Code AgentsThe idea is: instead of outputting a simple JSON object, a Code Agent generates an executable code block—typically in a high-level language like Python.For example, a Code Agent tasked with fetching the weather might generate the following Python snippet:# Code Agent Example: Retrieve Weather Informationdef get_weather(city):    import requests    api_url = f\"https://api.weather.com/v1/location/{city}?apiKey=YOUR_API_KEY\"    response = requests.get(api_url)    if response.status_code == 200:        data = response.json()        return data.get(\"weather\", \"No weather information available\")    else:        return \"Error: Unable to fetch weather data.\"# Execute the function and prepare the final answerresult = get_weather(\"New York\")final_answer = f\"The current weather in New York is: {result}\"print(final_answer)Observe: Integrating Feedback to Reflect and AdaptObservations are how an Agent perceives the consequences of its actions.They are signals from the environment—whether it’s data from an API, error messages, or system logs—that guide the next cycle of thought.In the observation phase, the agent:  Collects Feedback: Receives data or confirmation that its action was successful (or not).  Appends Results: Integrates the new information into its existing context, effectively updating its memory.  Adapts its Strategy: Uses this updated context to refine subsequent thoughts and actions.Type of Observation:  System Feedback: Error messages, success notifications, status codes  Data Changes: Database updates, file system modifications, state changes  Environmental Data: Sensor readings, system metrics, resource usage  Response Analysis: API responses, query results, computation outputs  Time-based Events: Deadlines reached, scheduled tasks completedDummy Agent Library        Let’s Create Our First Agent Using smolagentsWhat is smolagents?Smolagents is a library that focuses on codeAgent, a kind of agent that performs “Actions” through code blocks, and then “Observes” results by executing the code.Lightweight library is designed for simplicity, but it abstracts away much of the complexity of building an Agent, allowing you to focus on designing your agent’s behavior.We provided our agent with an Image generation tool and asked it to generate an image of a cat.The agent inside smolagents is going to have the same behaviors as the custom one we built previously: it’s going to think, act and observe in cycle until it reaches a final answer.Let’s build our Agent!        Fine tuning LLM for function callingFunction-calling is a way for an LLM to take actions on its environment. It was first introduced in GPT-4, and was later reproduced in other models.Just like the tools of an Agent, function-calling gives the model the capacity to take an action on its environment. However, the function calling capacity is learned by the model, and relies less on prompting than other agents techniques.During Unit 1, the Agent didn’t learn to use the Tools, we just provided the list, and we relied on the fact that the model was able to generalize on defining a plan using these Tools.Huggingface course        Start from https://huggingface.co/google/gemma-2-2b-it, a model that has been trained for instruction following (instruction tuned). Instruction tuned models introduce extra tokens to the vocabulary to help the model understand the instructions; examples are &lt;start_of_turn&gt; and &lt;end_of_turn&gt; in the case of gemma.The tokenizer provides a built-in chat template that can be used to format the conversation as a list of messages. As an example, the following chart:chat = [    { \"role\": \"user\", \"content\": \"Write a hello world program\" },]Ran through the tokenizer’s chat template:prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)Will output:&lt;bos&gt;&lt;start_of_turn&gt;userWrite a hello world program&lt;end_of_turn&gt;&lt;start_of_turn&gt;modelNousResearch/hermes-function-calling-v1 DataSetA popular Dataset for function calling with 11578 examples. Here’s an example:[    {        \"from\": \"system\",        \"value\": \"You are a function calling AI model. You are provided with function signatures within &lt;tools&gt; &lt;/tools&gt; XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. &lt;tools&gt; [{'type': 'function', 'function': {'name': 'get_camera_live_feed', 'description': 'Retrieves the live feed from a specified security camera.', 'parameters': {'type': 'object', 'properties': {'camera_id': {'type': 'string', 'description': 'The unique identifier for the camera.'}, 'stream_quality': {'type': 'string', 'description': 'The desired quality of the live stream.', 'enum': ['720p', '1080p', '4k']}}, 'required': ['camera_id']}}}, {'type': 'function', 'function': {'name': 'list_all_cameras', 'description': 'Lists all the security cameras connected to the home network.', 'parameters': {'type': 'object', 'properties': {'include_offline': {'type': 'boolean', 'description': 'Whether to include cameras that are currently offline.', 'default': False}}, 'required': []}}}, {'type': 'function', 'function': {'name': 'record_camera_feed', 'description': 'Starts recording the live feed from a specified security camera.', 'parameters': {'type': 'object', 'properties': {'camera_id': {'type': 'string', 'description': 'The unique identifier for the camera.'}, 'duration': {'type': 'integer', 'description': 'The duration in minutes for which to record the feed.', 'default': 60}}, 'required': ['camera_id']}}}, {'type': 'function', 'function': {'name': 'get_recorded_feed', 'description': 'Retrieves a previously recorded feed from a specified security camera.', 'parameters': {'type': 'object', 'properties': {'camera_id': {'type': 'string', 'description': 'The unique identifier for the camera.'}, 'start_time': {'type': 'string', 'description': 'The start time of the recording to retrieve, in ISO 8601 format.'}, 'end_time': {'type': 'string', 'description': 'The end time of the recording to retrieve, in ISO 8601 format.'}}, 'required': ['camera_id', 'start_time', 'end_time']}}}, {'type': 'function', 'function': {'name': 'pan_tilt_camera', 'description': 'Controls the pan and tilt functions of a PTZ (Pan-Tilt-Zoom) security camera.', 'parameters': {'type': 'object', 'properties': {'camera_id': {'type': 'string', 'description': 'The unique identifier for the PTZ camera.'}, 'pan_angle': {'type': 'integer', 'description': 'The angle in degrees to pan the camera. Positive values pan right, negative values pan left.'}, 'tilt_angle': {'type': 'integer', 'description': 'The angle in degrees to tilt the camera. Positive values tilt up, negative values tilt down.'}}, 'required': ['camera_id', 'pan_angle', 'tilt_angle']}}}] &lt;/tools&gt; For each function call return a json object with function name and arguments within &lt;tool_call&gt; &lt;/tool_call&gt; tags with the following schema: &lt;tool_call&gt; {'arguments': &lt;args-dict&gt;, 'name': &lt;function-name&gt;} &lt;/tool_call&gt; \"    },    {        \"from\": \"human\",        \"value\": \"I've recently installed a new security system at my home, and I want to ensure everything is functioning as it should. Specifically, I'd like to start by checking the live feed from the camera located at the front door to monitor any activity. The camera has a unique identifier, which I've already configured to be \"front_door.\" I'd prefer to view the live stream in high definition, so a 1080p quality would be ideal. Could you please call the appropriate function to retrieve the live feed from my front door camera in 1080p quality and provide me with the link to the stream? Following this, I would also like to record the live feed from this camera for the next 30 minutes. This is to test the recording feature and to keep an archived copy for security purposes. Please initiate the recording function for the \"front_door\" camera with a recording duration of 30 minutes. Lastly, as part of my routine surveillance checks, I need to review footage from yesterday between 3 PM and 5 PM. The camera \"front_garden\" should have the recording for that period. I need to retrieve this specific recorded feed. The start time for the recording was at 15:00 on April 22, 2023, and it ended at 17:00 on the same day. To summarize, I request the execution of the following functions with the provided details: 1. Retrieve the live feed from the \"front_door\" camera at 1080p quality. 2. Start a 30-minute recording of the live feed from the \"front_door\" camera. 3. Retrieve the recorded feed from the \"front_garden\" camera, focusing on the time period between 15:00 and 17:00 on April 22, 2023. Thank you for assisting with the management of my home security camera feeds.\"    },    {        \"from\": \"gpt\",        \"value\": \"&lt;tool_call&gt; {'arguments': {'camera_id': 'front_door', 'stream_quality': '1080p'}, 'name': 'get_camera_live_feed'} &lt;/tool_call&gt; &lt;tool_call&gt; {'arguments': {'camera_id': 'front_door', 'duration': 30}, 'name': 'record_camera_feed'} &lt;/tool_call&gt; &lt;tool_call&gt; {'arguments': {'camera_id': 'front_garden', 'start_time': '2023-04-22T15:00:00Z', 'end_time': '2023-04-22T17:00:00Z'}, 'name': 'get_recorded_feed'} &lt;/tool_call&gt; \"    }]Now, this dataset does not contain the thinking part, so we need to add it. See next.hermes-function-calling-thinking-V1 DataSetContains a single split called “train” with 3570 examples:[     {         \"content\": \"You are a function calling AI model. You are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:&lt;tools&gt; [{'type': 'function', 'function': {'name': 'get_stock_price', 'description': 'Get the current stock price of a company', 'parameters': {'type': 'object', 'properties': {'company': {'type': 'string', 'description': 'The name of the company'}}, 'required': ['company']}}}, {'type': 'function', 'function': {'name': 'get_movie_details', 'description': 'Get details about a movie', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the movie'}}, 'required': ['title']}}}] &lt;/tools&gt;Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags as follows:\\n&lt;tool_call&gt;\\n{tool_call}\\n&lt;/tool_call&gt;\",         \"role\": \"system\"     },     { \"content\": \"Hi, can you tell me the current stock price of Apple?\",         \"role\": \"human\"     },     {         \"content\": \"&lt;think&gt;Alright, the user asked for the current stock price of Apple. Looking at the tools available, there's a function called get_stock_price which exactly fits this request. I'll need to call this function with the parameter company set to 'Apple' to retrieve the information the user is asking for. This seems like the most straightforward and appropriate action to take.\\n&lt;/think&gt;&lt;tool_call&gt;\\n{'name': 'get_stock_price', 'arguments': {'company': 'Apple'}}\\n&lt;/tool_call&gt;\",         \"role\": \"model\"     },     {         \"content\": \"&lt;tool_response&gt;\\n{'stock_price': '$150.75'}\\n&lt;/tool_response&gt;\",         \"role\": \"tool\"     },     { \"content\": \"The current stock price of Apple is $150.75.\",         \"role\": \"model\"     },     {         \"content\": \"That's great. Can you also tell me the stock price for Microsoft?\",         \"role\": \"human\"     },     {         \"content\": \"&lt;think&gt;Alright, let me try to figure out how to handle this user's request. The user first asked about Apple's stock price, and I responded by calling the get_stock_price function with 'Apple' as the argument. The tool provided the price, and I passed that information back to the user.\\n\\nNow, the user is asking for the stock price of Microsoft. I need to determine the appropriate action here. Looking at the tools available, there's still the get_stock_price function, which is designed to fetch current stock prices. Since the user is requesting another company's stock price, it makes sense to use the same function again but with the company name changed to Microsoft. \\n\\nI shouldn't assume any other tools are needed because the available functions are specifically tailored for stock prices and movie details. In this case, the relevant function is get_stock_price. I should ensure that the function is called with the correct parameter, 'Microsoft' in this case, to retrieve the accurate information the user is seeking. This approach is efficient and aligns directly with the user's request without making unnecessary assumptions or using unrelated tools.\\n&lt;/think&gt;&lt;tool_call&gt;\\n{'name': 'get_stock_price', 'arguments': {'company': 'Microsoft'}}\\n&lt;/tool_call&gt;\",         \"role\": \"model\"     },     {         \"content\": \"&lt;tool_response&gt;\\n{'stock_price': '$210.22'}\\n&lt;/tool_response&gt;\",         \"role\": \"tool\"     },     {         \"content\": \"The current stock price of Microsoft is $210.22.\",         \"role\": \"model\"     },     {         \"content\": \"Thank you for the information.\",         \"role\": \"human\"     },     {         \"content\": \"You're welcome! If you have any other questions, feel free to ask.\",         \"role\": \"model\"     } ]"
  },
  
  {
    "title": "ChatGPT-like systems",
    "url": "/posts/ChatGPT-like-systems/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, deepseek",
    "date": "2025-02-06 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "DeepSeek Paper",
    "url": "/posts/deepseek-paper-copy/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, deepseek",
    "date": "2025-02-03 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "RNN from scratch",
    "url": "/posts/rnn-from-scratch/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, rnn",
    "date": "2024-12-16 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "SoftMax",
    "url": "/posts/softmax/",
    "categories": "Blogging, Tutorial",
    "tags": "probabilities, softmax",
    "date": "2024-12-11 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Cross Entropy Loss",
    "url": "/posts/cross-entropy-loss/",
    "categories": "Blogging, Tutorial",
    "tags": "probabilities, cross-entropy-loss",
    "date": "2024-12-11 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Recurrent neural networks",
    "url": "/posts/recurrent-neural-networks/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, rnn",
    "date": "2024-12-10 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Python Pandas",
    "url": "/posts/pandas/",
    "categories": "Blogging, Tutorial",
    "tags": "pandas",
    "date": "2024-12-06 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "LLM Fine-Tuning on Your Own Docs",
    "url": "/posts/llm-fine-tuning-on-your-own-docs/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, fine-tuning, llms",
    "date": "2024-11-20 11:08:03 +0200",
    





    
    "snippet": "Fine-tuning LLMs on your own documents        ReferencesFine-tune a model on your own documentation",
    "content": "Fine-tuning LLMs on your own documents        ReferencesFine-tune a model on your own documentation"
  },
  
  {
    "title": "HuggingFace",
    "url": "/posts/huggingface/",
    "categories": "Blogging, Tutorial",
    "tags": "huggingface, transformers",
    "date": "2024-11-18 11:08:03 +0200",
    





    
    "snippet": "HuggingfaceTransformers Library        References            [The Hugging Face Transformers Library      Example Code + Chatbot UI with Gradio](https://www.youtube.com/watch?v=jan07gloaRg)      ",
    "content": "HuggingfaceTransformers Library        References            [The Hugging Face Transformers Library      Example Code + Chatbot UI with Gradio](https://www.youtube.com/watch?v=jan07gloaRg)      "
  },
  
  {
    "title": "BERT fine tuning for phishing URL detection.",
    "url": "/posts/bert-fine-tuning/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, bert, finetuning",
    "date": "2024-11-14 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Quotes",
    "url": "/posts/quotes/",
    "categories": "Blogging",
    "tags": "",
    "date": "2024-11-09 11:08:03 +0200",
    





    
    "snippet": "  There is an enthusiasm to step down from the limitations of accepted order into the limitless potential of chaos but too often this step is regarder as an achievement in itself rather than only t...",
    "content": "  There is an enthusiasm to step down from the limitations of accepted order into the limitless potential of chaos but too often this step is regarder as an achievement in itself rather than only the first stage towards achivement. – Edward de Bono, Lateral Thinking."
  },
  
  {
    "title": "Stable Diffusion",
    "url": "/posts/stable-diffusion/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, stablediffusion",
    "date": "2024-11-06 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "LLaMA",
    "url": "/posts/llama-2/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, llm, llama",
    "date": "2024-11-06 11:08:03 +0200",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "CNNs",
    "url": "/posts/cnn/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, cnn",
    "date": "2024-10-22 12:08:03 +0300",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Autoencoders",
    "url": "/posts/autoencoders/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, autoencoders",
    "date": "2024-10-18 12:08:03 +0300",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Transformers",
    "url": "/posts/transformers/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, transformers",
    "date": "2024-10-15 12:08:03 +0300",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Retrieval Augmented Generation",
    "url": "/posts/retrieval-augmented-generation/",
    "categories": "Blogging, Tutorial",
    "tags": "rag, llm, llamaindex",
    "date": "2024-10-11 12:08:03 +0300",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Multi Layer Perceptron",
    "url": "/posts/mlp/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, mlp",
    "date": "2024-10-11 12:08:03 +0300",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Linear Algebra",
    "url": "/posts/linear-algebra/",
    "categories": "Blogging, Tutorial",
    "tags": "linearalgebra, vectors, dotproduct",
    "date": "2024-10-08 12:08:03 +0300",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "LSTM",
    "url": "/posts/lstm/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, rnn, lstm",
    "date": "2024-10-07 12:08:03 +0300",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Learning Neural Nets",
    "url": "/posts/learning-neural-networks/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks",
    "date": "2024-10-05 01:08:03 +0300",
    





    
    "snippet": "Linear Algebra            Link      Description                  Linear Algebra      3Blue1Brown Series on Linear Algebra              Mathematics for Machine Learning      Imperial College London ...",
    "content": "Linear Algebra            Link      Description                  Linear Algebra      3Blue1Brown Series on Linear Algebra              Mathematics for Machine Learning      Imperial College London Course on  Mathematics for Machine Learning              A Mathematical Framework for Transformer Circuits      Anthropic’s Mathematical Framework for Transformers              Machine Learning Foundations      Machine Learning Foundations      Calculus            Link      Description                  Calculus      3Blue1Brown’s series on calculus.              MIT Calculus 1A: Differentiation      Calculus 1A by MIT.              Understanding Calculus: Problems, Solutions, and Tips      A course offering various problems, solutions, and tips for understanding calculus.              Machine Learning Foundations      Machine Learning Foundations      Differentiable Programming            Link      Description                  Google Deepmind: The Elements of Differentiable Programming      The mathematical frameworks that underpins “Differentiable Programming”      Neural Networks            Link      Description                  Before Language Models - N-Ggram      An article on the Wikipedia page for Word n-gram language model.              Neural Networks      3Blue1Brown’s series on neural networks.              Karpathy’s Neural Networks: Zero to Hero      Andrej Karpathy’s series on neural networks              Build GPT from scratch      Andrej Karpathy: Let’s build GPT: from scratch, in code, spelled out.              Umar Jamil’s youtube channel      Umar Jamil’s youtube channel.              Shawhin Talebi’s youtube channel      Shawhin Talebi’s youtube channel.      Architectures            Domain      Problem      Architecture                  Computer Vision      Image classification      CNNs, ResNet, EfficientNet, Vision Transformers (ViT)                     Object detection      YOLO, Faster R-CNN, RetinaNet, DETR                     Image segmentation      U-Net, Mask R-CNN, DeepLabV3                     Image generation      GANs, Variational Autoencoders (VAEs)                     Style transfer      Neural Style Transfer Networks              Natural Language Processing (NLP)      Text classification      RNNs, BiLSTMs, Transformers, BERT                     Sentiment analysis      RNNs, BiLSTMs, Transformers, BERT                     Machine translation      Seq2Seq Models, Transformers, MarianMT, T5                     Text summarization      Transformers, BART, Pegasus                     Question answering      BERT, RoBERTa, ALBERT                     Text generation      GPT, LLaMA              Speech Processing      Speech recognition      RNNs with CTC Loss, Wav2Vec 2.0, Conformer                     Speech synthesis      Tacotron 2, WaveNet, VITS                     Speaker identification      CNNs, ResNet-based models              Time-Series Analysis      Forecasting      LSTMs, GRUs, Temporal Fusion Transformer                     Anomaly detection      Autoencoders, LSTMs                     Activity recognition      CNNs, RNNs, Temporal Convolutional Networks (TCNs)              Reinforcement Learning      Game playing      Deep Q-Networks (DQNs), AlphaZero, PPO                     Robotics control      Policy Gradient Methods, SAC, TD3                     Strategy optimization      A3C, PPO              Generative Modeling      Text-to-image generation      Stable Diffusion, DALL-E                     Data augmentation      GANs, VAEs                     Synthetic data generation      GANs, Diffusion Models              Medical Applications      Disease detection      CNNs, Vision Transformers (ViT)                     Medical image segmentation      U-Net, SegNet                     Drug discovery      Graph Neural Networks (GNNs), Transformer-based models (e.g., MolBERT)              Graph-Based Problems      Social network analysis      Graph Neural Networks (GNNs), Graph Convolutional Networks (GCNs)                     Knowledge graph completion      Graph Attention Networks (GATs), TransE                     Molecular structure prediction      Message Passing Neural Networks (MPNNs)              Recommendation Systems      Product recommendation      Collaborative Filtering Models, Autoencoders, Neural Collaborative Filtering (NCF), Transformers                     Content personalization      Collaborative Filtering Models, Autoencoders, Transformers                     Collaborative filtering      Collaborative Filtering Models, Neural Collaborative Filtering (NCF)              Control Systems      Autonomous driving      Convolutional Networks, Reinforcement Learning with sensor integration                     Industrial process optimization      Recurrent Neural Networks, Reinforcement Learning              Multimodal Learning      Image and text alignment      CLIP, ViLBERT                     Audio-visual synchronization      Multimodal Transformers, Hybrid CNN-RNN Architectures      "
  },
  
  {
    "title": "Probabilities",
    "url": "/posts/probabilities/",
    "categories": "Blogging, Tutorial",
    "tags": "probabilities",
    "date": "2024-10-04 12:08:03 +0300",
    





    
    "snippet": "        ",
    "content": "        "
  },
  
  {
    "title": "Optimizations",
    "url": "/posts/optimizations/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, optimizations, quantization",
    "date": "2024-10-03 12:08:03 +0300",
    





    
    "snippet": "Quantization        Knowledge DistillationTransfer the knowledge of a larger (teacher) model to a smaller (student) one.Soft targets: train student using logits of the teacher. During training, the...",
    "content": "Quantization        Knowledge DistillationTransfer the knowledge of a larger (teacher) model to a smaller (student) one.Soft targets: train student using logits of the teacher. During training, the teacher’s logits are used as targets for the student.Synthetic data: generate synthetic data from the teacher’s predictions.SparsityTorch compilerReferencesGPU MODE IRL 2024 KeynotesQuantization explained with PyTorch - Post-Training Quantization, Quantization-Aware TrainingKnowledge Distillation"
  },
  
  {
    "title": " Neural Networks Backpropagation",
    "url": "/posts/backpropagation/",
    "categories": "Blogging, Tutorial",
    "tags": "neuralnetworks, backpropagation",
    "date": "2024-01-03 11:08:03 +0200",
    





    
    "snippet": "GradientVideoThe gradient captures all the partial derivative information of a scalar-valued multivariable function. Created by Grant Sanderson.A vector of partial derivatives for a multivariate fu...",
    "content": "GradientVideoThe gradient captures all the partial derivative information of a scalar-valued multivariable function. Created by Grant Sanderson.A vector of partial derivatives for a multivariate function.Gives the direction of steepest ascent (descent) of the function.The directional derivativeThe directional derivative is the dot product between the gradient and the unit vector in that direction.In our case we have the C as the cost function, and the partial derivatives for the weights and biases. We want to descent the gradient of the cost function.The dimensionality of the gradient space is given by the number of weights and biases for the model.The chain ruleThe chain rule tells us that the derivative of a composite function is equal to the product of the derivatives of each of its parts.df(g(x))/dx = df/dg * dg/dxWe have a cost function L, and we want to find the partial derivative of L with respect to each parameter. We can do that by using the chain rule:if L = fg, and f=h+k =&gt; dL/df = g, dL/dg = f, df/dh = 1, df/dk = 1. Using the chain rule, dL/dh = dL/dfdf/dh and so on. dL/dh is the gradient of h; how much does h impact the gradient descent.Remarks:  a plus sign distributes the gradient of a parent to its children.  we can only influence leaf nodes during gradinet descent. In the example above, we can only influence h,k and g  because a parameter can be referenced more than once, the gradients have to be summed up instead of overwritted at parameter level.NeuronWe have n inputs, x-es each with a weight, w-s. And a bias b. Then we have an activation function f, a squashing function. The value of the neuron is f(sum(xi*wi) + b).LayerA set of n neuronsMLP: multi-layer perceptronA chaining of multiple layers: An input layer, 0 to multiple hidden layers and the output layer. Each neuron in Layer n is connected to each neuron in Layer n-1.A forward pass: we take a set of input values and forward pass through the entire network. There’s an activation function at the end with the main goal of squashing the values. Why do we need squashing: to make sure that the output is bounded between 0 and 1. We call the output of this layer the activations. Multiple samples are processed in parallel in a batch and a loss or cost function is computed over the predictions of each sample versus the extected values.Backward propagation is called on the loss function to calculate the gradients for each parameter over the entire batch. Based on the gradients, we update the parameters in the direction that reduces the loss (the gradient descent).How to choose a proper learning rate?Instead of a static learning rate, build a dynamic learning rate with the powers of 10 between -3 and 0; 1000 of themlre = torch.linspace(-3, 0, 1000)lrs = 10**lreThis will be between 0.001 and 1, but exponentiated.Run a training loop with the dynamic learning rate, save the loss and plot it. You get something like this:So the best rate is between the -1 and -0.5 exponent of 10.How to arrange the dataHave 3 splits for the dataset:  Training set (80%) - used to optimize the parameters  Validation set (10%) - used for development of the hiperparameters (size of the emb, batch etc)  Test set (10%) - used at the end to test the final model.LogitsThe logits are the raw output of the neural network before passing them through an activation function.Activation functionsAn activation function is used to introduce non-linearity in the model, and it’s usually applied at the end of the linear part of the network. Examples of activation functions are: ReLU, LeakyReLU, ELU, SELU, Sigmoid, Tanh and many more.The distribution for a not-normalized activation function for 32 samples on 200 newuronsThis is triggered by the preactivations that are widely distributed. Whatever is lower than -1 is squashed into -1 and whatever is higher than +1 is squashed into +1.The problem is that during differentiatiation, in 1 and -1, it goes to 0 and makes the network untrainable, that newuron will not learn anything. It’s called a dead neuron.How to solve it: normalize at initialization the parameters that contribute to the preactivations:W1 = torch.randn((block_size * n_embed, n_hidden), generator=g) * 0.2b1 = torch.randn(n_hidden, generator=g) * 0.01SoftmaxThe softmax is a normalizing function that converts the logits into probabilities. At the beginning the softmax can be confidently wrong. That’s because the parameters are not normalized and the preactivations are widely distributed.How to solve it: normalize at initialization the parameters that contribute to the logits, hence softmax:W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01b2 = torch.randn(vocab_size, generator=g) * 0NormalizationHow to get rid of the magic numbers used in the previous examples? What we want is a unit gaussian data distribution. That means, a standard deviation of one.Divide the parameters by the square root of the fan-in. The fan-in is the number of inputs that a neuron receives. Multiple it with a gain, that in case of tanh is 5/3. See torch.nn.initBatch normalizationNormalize the preactivation to be unit gaussian. The mean and standard deviation are computed over the batch dimension.    hpreact = bngain * ((hpreact - hpreact.mean(0, keepdim=True))/hpreact.std(0, keepdim=True)) + bnbiasbngain and bnbias are learnable parameters introduced in order to allow the training to go outside of the unit gaussian."
  }
  
]

